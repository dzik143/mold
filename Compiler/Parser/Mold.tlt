<?xml version="1.0" standalone="yes"?>
<generator name="Mold">
  <code_localization />

  <!--
################################################################################
#                                                                              #
# This file is part of Mold project.                                           #
# Copyright (C) 2015, 2020 Sylwester Wysocki (sw143@wp.pl)                     #
#                                                                              #
# This program is free software: you can redistribute it and/or modify         #
# it under the terms of the GNU General Public License as published by         #
# the Free Software Foundation, either version 3 of the License, or            #
# (at your option) any later version.                                          #
#                                                                              #
# This program is distributed in the hope that it will be useful,              #
# but WITHOUT ANY WARRANTY; without even the implied warranty of               #
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the                #
# GNU General Public License for more details.                                 #
#                                                                              #
# You should have received a copy of the GNU General Public License            #
# along with this program. If not, see <http://www.gnu.org/licenses/>          #
#                                                                              #
################################################################################
  -->

  <!--
  ****************************************************************************
  Escape sequences
  ****************************************************************************
  -->

  <!-- FIXME -->
  <!-- Backslash must be double-quoted -->
  <escape-sequence for="\" do= />
  <!-- Escape double quotation marks -->
  <escape-sequence for="&#x22;" do= />
  <!-- END OF FIXME -->

  <!--
  ****************************************************************************
  Value-stack templates
  ****************************************************************************
  -->

  <vstack_def_type>any</vstack_def_type>
  <vstack_term_type>any</vstack_term_type>
  <vstack_union_att>@@value-type-id</vstack_union_att>
  <vstack_union_def>@@attribute: null, </vstack_union_def>
  <vstack_single>value: null</vstack_single>
  <vstack_union_start>value: {</vstack_union_start>
  <vstack_union_end>}</vstack_union_end>

  <!--
  ****************************************************************************
  Semantic action templates
  ****************************************************************************
  -->
  <action_start>        elif currentIdx is @@production-number
      </action_start>
  <action_end>

</action_end>

  <action_single>stackValues[stackIdx - @@offset]</action_single>

  <action_union>stackValues[stackIdx - @@offset].@@attribute</action_union>
  <action_lhs_single>     currentRet</action_lhs_single>
  <action_lhs_union>     currentRet.@@attribute</action_lhs_union>

  <action_set_lhs>     currentLhs = @@sym</action_set_lhs>

  <!--
  ****************************************************************************
  Semantic terminal action templates
  ****************************************************************************
  -->

  <scan_action_start>&#x09;&#x09;&#x09;&#x09;case @@symbol-number:&#x0A;&#x09;&#x09;&#x09;&#x09;{&#x0A;&#x09;&#x09;&#x09;&#x09;&#x09;</scan_action_start>
  <scan_action_end>&#x0A;&#x09;&#x09;&#x09;&#x09;&#x09;;&#x0A;&#x09;&#x09;&#x09;&#x09;}&#x09;&#x09;&#x09;&#x09;break;
  </scan_action_end>

  <scan_action_begin_offset>@@prefix_lexem( pcb )</scan_action_begin_offset>
  <scan_action_end_offset>currentLen</scan_action_end_offset>

  <scan_action_ret_single>stackValues[stackIdx]</scan_action_ret_single>

  <!-- TODO: Is it needed?
    <scan_action_ret_union>stack[stackIdx].@@attribute</scan_action_ret_union>
  -->

  <scan_action_set_symbol>currentSym = @@sym</scan_action_set_symbol>

  <!--
  ****************************************************************************
  Parse table templates
  ****************************************************************************
  -->

  <defprod>
    <col>@@production-number</col>
    <col_sep>, </col_sep>
  </defprod>

  <acttab>
    <row_start>  [ </row_start>
    <row_end> ]</row_end>
    <row_sep>,&#x0A;</row_sep>
    <col> @@symbol,@@index,@@action </col>
    <col_sep>,</col_sep>
  </acttab>

  <gotab>
    <row_start>  [ </row_start>
    <row_end> ]</row_end>
    <row_sep>,&#x0A;</row_sep>
    <col> @@symbol,@@index,@@action </col>
    <col_sep>,</col_sep>
  </gotab>

  <!--
  ****************************************************************************
  Lexer
  ****************************************************************************
  -->

  <dfa_select>
    <col>@@machine</col>
    <col_sep>, </col_sep>
  </dfa_select>

  <dfa_char>
    <col>@@from, @@to</col>
    <col_sep>, </col_sep>
  </dfa_char>

  <dfa_trans>
    <col>@@goto</col>
    <col_sep>, </col_sep>
  </dfa_trans>

  <dfa_idx>
    <row_start>  [ </row_start>
    <row_end> ]</row_end>
    <row_sep>,&#x0A;</row_sep>
    <col>@@index * 2</col>
    <col_sep>, </col_sep>
  </dfa_idx>

  <dfa_accept>
    <row_start>  [ </row_start>
    <row_end> ]</row_end>
    <row_sep>,&#x0A;</row_sep>
    <col>@@accept</col>
    <col_sep>, </col_sep>
  </dfa_accept>

  <!--
  ****************************************************************************
  Symbol and production information tables
  ****************************************************************************
  -->

  <symbols>
    <col>&#x0A;        { /* @@symbol */ symbol: "@@symbol-name", emit: "@@emit", isTerminal: @@type, isLexem: @@lexem, isWhitespace: @@whitespace, isGreedy: @@greedy }</col>
    <col_sep>,</col_sep>
  </symbols>

  <productions>
    <col>&#x0A;        { /* @@production-number */ production: "@@production", emit: "@@emit", length: @@length, lhs: @@lhs }</col>
    <col_sep>,</col_sep>
  </productions>

  <!--
  ****************************************************************************
                           LALR(1) Parser program
  ****************************************************************************
  -->

<file filename="_Parser.mold"># Parser module generated by unicc from @@filename.
# DO NOT EDIT THIS FILE MANUALLY, IT WILL GO AWAY!
@@prologue

################################################################################
#                                                                              #
# This file is part of Mold project.                                           #
# Copyright (c) 2015, 2018 Sylwester Wysocki (sw143@wp.pl).                    #
#                                                                              #
# The Mold code and any derived work however based on this software are        #
# copyright of Sylwester Wysocki. Redistribution and use of the present        #
# software is allowed according to terms specified in the file LICENSE         #
# which comes in the source distribution.                                      #
#                                                                              #
# All rights reserved.                                                         #
#                                                                              #
################################################################################

import './_Tables.mold'

# -----------------------------------------------------------------------------
#                                Constants
# -----------------------------------------------------------------------------

UNICC_ERROR  = 0
UNICC_REDUCE = 1
UNICC_SHIFT  = 2

PRODUCTION_EMIT_IDX   = 0
PRODUCTION_LENGTH_IDX = 1
PRODUCTION_LHS_IDX    = 2

SCANERLESS_MODE_ENABLED = (@@number-of-dfa-machines > 1)

# -----------------------------------------------------------------------------
#                                Helper classes
# -----------------------------------------------------------------------------

#
# Abstract Syntax Tree
#

NodeId = 0

class AST
  method constructor(opcode, value, child)
    global NodeId

    this.opcode = opcode
    this.value  = value
    this.id     = NodeId

    this.children = []
    this.parent   = null
    this.next     = null

    NodeId = NodeId + 1

    # TODO: Clean up this mess.
    # Collect children.
    node = child
    while node is defined
      node.parent               = this
      this.children[@afterlast] = node
      # Go to next child if any.
      node = node.next
    endwhile
  endmethod

  method _printTreeInternal(node, deepIdx)
    prefix = ''
    for i in 0 .. deepIdx
      prefix = prefix ~ '..'
    endfor

    if node.value is defined
      print prefix ~ '#' ~ str(node.id), node.opcode, node.value
    else
      print prefix ~ '#' ~ str(node.id), node.opcode
    endif

    for values oneChild in node.children
      this._printTreeInternal(oneChild, deepIdx + 1)
    endfor
  endmethod

  method printTree()
    print '----------------------------------'
    print ' Abstract Syntax Tree'
    print '----------------------------------'
    this._printTreeInternal(this, 0)
  endmethod
endclass

# -----------------------------------------------------------------------------
#                                Parser class
# -----------------------------------------------------------------------------

class Parser
  method constructor()
    # Map of collected explicit constants.
    # TODO: Handle per module constants.
    this.constantsMap = {}
  endmethod

  method _handleError(line, column, msg)
    die(this.filePath ~ ':' ~ str(line) ~ ':' ~ str(column) ~ ': error: ' ~ msg)
  endmethod

  method _parseInternal(text) -> ast
    global UNICC_ERROR, UNICC_REDUCE, UNICC_SHIFT
    global PRODUCTION_LHS_IDX
    global PRODUCTION_LENGTH_IDX
    global PRODUCTION_EMIT_IDX
    global SCANERLESS_MODE_ENABLED

    global GrammarProductionsLUT
    global SymbolsGreedyLUT

    global ParserActionsLUT
    global ParserActionsDefaultLUT
    global ParserGotoLUT

    global LexerSelectLUT
    global LexerIndexLUT
    global LexerCharsLUT
    global LexerTransLUT
    global LexerAcceptLUT

    ast        = null
    goOn       = true
    masterIter = 1

    #
    # Initialize Parser Control Block.
    #

    input    = text
    inputIdx = 0
    inputLen = len(text)
    line     = 1
    column   = 1

    # Buffer first lookup byte.
    # TODO: Clean up this mess.
    lookupByte = @@eof
    if inputLen > 0
      lookupByte = ord(input[0])
    endif

    inputIdx = 1

    # Map of collected explicit constants.
    constantsMap = this.constantsMap

    # Current parser state.
    currentAct = 0
    currentIdx = 0
    currentLhs = 0
    currentRet = null

    stackIdx     = 0
    stackValues  = [null]
    stackNodes   = [null]
    stackStates  = [0]
    stackLines   = [0]
    stackColumns = [0]

    # TODO: Crash on one-character byte.
    # TODO: Clean up this mess.
    buf = '' ~ asc(lookupByte)

    # Current lexer token.
    currentSym = 0
    currentLen = 0

    #
    # Begin of main parser loop
    #

    while goOn is true

      # -----------------------------------------
      # LEXER: Get next symbol from input stream.
      # -----------------------------------------

      # print '------------------'

      if SCANERLESS_MODE_ENABLED is true
        # Lexer (scanner) is joined with parser.
        # There are potentialy many different lexers (DFAs) depending
        # on current parser state.
        mach       = LexerSelectLUT[stackStates[stackIdx]]
        currentSym = 0
        currentLen = 0

      else
        # There is one lexer.
        # Lexer works separately as input for parser.
        # [source code] -> [Lexer] -> [Parser] -> [AST output]
        mach = 0
      endif

      indexBase = LexerIndexBaseLUT[mach]
      indexRow  = LexerIndexLUT[mach]
      acceptRow = LexerAcceptLUT[mach]

      if (mach > -1) and (currentSym is 0)
        length     = 0
        chr        = 0
        next       = ord(buf[0])
        lexerState = 0

        # print '(', stackIdx, ') lexer'

        # Read next token. if there is still some input data to read.
        while (lexerState &gt;= 0) and (next isnt @@eof)
          isMatched  = false
          chr        = indexBase + indexRow[lexerState]
          lexerState = -1

          # Match character.
          while (isMatched is false) and (LexerCharsLUT[chr] &gt; -1)
            if (next &gt;= LexerCharsLUT[chr]) and (next &lt;= LexerCharsLUT[chr + 1])
              isMatched = true
            else
              chr = chr + 2
            endif
          endwhile

          if isMatched is true
            lexerState = LexerTransLUT[chr // 2]

            if acceptRow[lexerState] &gt; 0
              currentLen = length + 1
              currentSym = acceptRow[lexerState] - 1

              if (currentSym is 0) or (SymbolsGreedyLUT[currentSym] is 0)
                # End of file or non-greedy symbol.
                lexerState = -1
              endif
            endif

            # Get next char from input.
            length              = length + 1
            numberOfBytesToRead = length - len(buf) + 2

            if numberOfBytesToRead > 0
              # Get next character from input stream
              lookupByte = ord(input[inputIdx])
              inputIdx   = inputIdx + 1
              buf        = buf ~ asc(lookupByte)
            endif

            next = ord(buf[length])
          endif
        endwhile
      endif

      # ------------------------------------
      # PARSER: Match symbol agains grammar.
      # ------------------------------------

      # TODO: Remove hardcoded token id for whitspaces ?
      if (SCANERLESS_MODE_ENABLED is false) and (currentSym is 54)
        # Skip all white spaces in classical one scaner / one parser flow.
        # Skip this one token and try another one on next iteration.
        # Update counters for line and column.
        for idx in 0 .. currentLen
          if ord(buf[idx]) is 10
            line   = line + 1
            column = 1
          else
            column = column + 1
          endif
        endfor

        # Pop token from the buffer.
        tmpBuf     = __mold_syscall(55, buf, currentLen, -1)
        buf        = tmpBuf
        currentSym = 0
        currentLen = 0

      else
        # Scanner-less mode or non-white token delivered from lexer.
        # Go on.

        # -------------------------------------
        # LALR: Find action for current symbol.
        # -------------------------------------

        # print '(', stackIdx, ') token', currentSym

        state      = stackStates[stackIdx]
        act        = ParserActionsLUT[state]
        cnt        = len(act)
        currentAct = -1
        actionIdx  = 0

        while (actionIdx &lt; cnt) and (currentAct is -1)
          if act[actionIdx] is currentSym
            currentIdx = act[actionIdx + 1]
            currentAct = act[actionIdx + 2]
          endif
          actionIdx = actionIdx + 3
        endwhile

        if currentAct is -1
          # Action not found.
          # Search default production as last try.
          currentIdx = ParserActionsDefaultLUT[state]

          if currentIdx &gt; -1
            # Reduce.
            currentAct = UNICC_REDUCE
          else
            # Syntax error.
            this._handleError(line, column, 'syntax error')
          endif
        endif

        # -----------
        # LALR: Shift
        # -----------

        if bitand(currentAct, UNICC_SHIFT) isnt 0
          # print '(', stackIdx, ') shift'

          stackIdx = stackIdx + 1

          # Execute scanner actions, if existing.
          # Here, UNICC_ON_SHIFT is set to 1, so that shifting-
          # related operations will be performed.
          # Scan actions.
          if false
          @@scan_actions
          endif

          stackStates[stackIdx]  = currentIdx
          stackLines[stackIdx]   = line
          stackColumns[stackIdx] = column
          stackNodes[stackIdx]   = null

          # Pop value from buffer.
          @@top-value = __mold_syscall(55, buf, 0, currentLen)

          # Update counters for line and column
          for idx in 0 .. currentLen
            if ord(buf[idx]) is 10
              line   = line + 1
              column = 1
            else
              column = column + 1
            endif
          endfor

          # TODO: Clean up this mess.
          # TODO: Avoid temp buffer: x = x.substr(...) bug.
          tmpBuf     = __mold_syscall(55, buf, currentLen, -1)
          buf        = tmpBuf
          currentSym = 0
          currentLen = 0
        endif

        # -------------
        # LALR: Reduce.
        # -------------

        reduceGoOn = true

        while (reduceGoOn is true) and (bitand(currentAct, UNICC_REDUCE) isnt 0)
          # Fetch current production.
          currentLhs              = GrammarProductionsLUT[3 * currentIdx + PRODUCTION_LHS_IDX]
          currentProductionLength = GrammarProductionsLUT[3 * currentIdx + PRODUCTION_LENGTH_IDX]
          currentEmit             = GrammarProductionsLUT[3 * currentIdx + PRODUCTION_EMIT_IDX]

          # Apply default action: @@ = @1
          # TODO: Review it.
          currentRet = stackValues[stackIdx - currentProductionLength + 1]

          # print '(', stackIdx, ') reduce [production:', currentIdx, currentProductionLength, ']'

          # -----------------------------
          # Custom action handlers.
          # Below code is auto-generated.
          # -----------------------------

          # Set default left-hand side
          # Run reduction code
          # TODO: Use switch
          if false
            @@actions
          endif

          # --------------------------
          # AST: Pop nodes from stack.
          # --------------------------

          # Pop nodes from the stack.
          stackIdx = stackIdx - currentProductionLength

          if currentProductionLength > 1
            # We need at least two AST nodes to connect.
            # We can ignore all production shorter than two.

            # Find first non-null node on stack.
            firstNodeIdx = stackIdx + 1
            firstNode    = stackNodes[firstNodeIdx]
            maxNodeIdx   = stackIdx + currentProductionLength

            while ((firstNode is undefined) and
                   (firstNodeIdx &lt; maxNodeIdx))

              firstNodeIdx = firstNodeIdx + 1
              firstNode    = stackNodes[firstNodeIdx]
            endwhile

            if firstNode is defined
              # At at least one non-null node found.
              # Join all neighbour nodes into one linked list.

              # Check is there neighbour available on left side.
              lnode = stackNodes[stackIdx]

              if lnode is defined
                # There is node on the left.
                # Start list from it.
                # lnode - r1 - r2 - r3 - ...
                prevNode = lnode

              else
                # There is no any node on the left.
                # Start new list from the scratch.
                # null - r1 - r2 - r3 - ...
                stackNodes[stackIdx] = firstNode
                prevNode             = null
              endif

              for k in 0 .. currentProductionLength
                currentNode = stackNodes[stackIdx + k + 1]

                if currentNode is defined
                  if prevNode is defined
                    # Make sure we append after last neighbour if more than one.
                    # It's not the last node on the left.
                    # Find the last one.
                    #
                    # prevNode - ... - currentNode - ...
                    #             ^
                    #      We skip this hole

                    while prevNode.next is defined
                      prevNode = prevNode.next
                    endwhile
                    prevNode.next = currentNode
                  endif

                  # Go to next node on the list.
                  prevNode = currentNode
                endif
              endfor
            endif
          endif

          # -------------------------------
          # AST: Create new node if needed.
          # -------------------------------

          if currentEmit isnt 0
            # Emit new AST node.
            # print '(', stackIdx, ') emit', currentEmit

            node                 = new AST(currentEmit, currentRet, stackNodes[stackIdx])
            stackNodes[stackIdx] = node

            # Save debug information inside node.
            node.line     = line
            node.column   = column
            node.filePath = this.filePath
          endif

          # Goal symbol reduced?
          if currentLhs is @@goal
            # Goal token matched.
            # Don't go on anymore.
            reduceGoOn = false

          else
            # Get goto.
            goIdx      = 0
            state      = stackStates[stackIdx]
            go         = ParserGotoLUT[state]
            cnt        = len(go)
            currentAct = -1

            # print '(', stackIdx, ') goto from state', state, '[ lhs =', currentLhs, ']'

            while (goIdx &lt; cnt) and (currentAct is -1)
              if go[goIdx] is currentLhs
                currentIdx = go[goIdx + 1]
                currentAct = go[goIdx + 2]
              endif
              goIdx = goIdx + 3
            endwhile

            # print '(', stackIdx, ') goto to', currentIdx, currentAct

            # Push new item to state stack.
            stackIdx               = stackIdx + 1
            stackNodes[stackIdx]   = null
            stackValues[stackIdx]  = currentRet
            stackLines[stackIdx]   = line
            stackColumns[stackIdx] = column
            stackStates[stackIdx]  = currentIdx
          endif
        endwhile

        # --------------------------
        # Check for final condition.
        # --------------------------

        if currentIdx is @@goal-production
          # All input is successfuly parsed.
          # Don't go on anymore.
          goOn = false
        endif

        # Avoid hung up on infinitely loop.
        masterIter = masterIter + 1
        if masterIter > 1000000
          die('MAX ITERS reached!')
        endif
      endif
    endwhile

    ast = stackNodes[0]
  endmethod

  method parseFile(path) -> ast
    # Load source code from file.
    source        = FileLoad(path)
    this.filePath = path

    # Parse source into AST tree.
    ast = this._parseInternal(source)
  endmethod

  method parseText(text) -> ast
    this.filePath = ''
    ast           = this._parseInternal(text)
  endmethod
endclass

</file>

  <!--
  ****************************************************************************
              JS Script to generate postprocessed parse table
  ****************************************************************************
  -->

<file filename="_BuildTables.js">
  // Parser module generated by unicc from @@filename.
  // DO NOT EDIT THIS FILE MANUALLY, IT WILL GO AWAY!

  const data = {
    "grammar": {
      "symbols": [@@symbols],
      "productions": [@@productions],
      "goal": @@goal
    },
    "lexer": {
      "select": [@@dfa-select],
      "index": [@@dfa-index],
      "chars": [@@dfa-char],
      "transitions": [@@dfa-trans],
      "accept": [@@dfa-accept]
    },
    "parser": {
      "action": [@@action-table],
      "goto": [@@goto-table],
      "default-production": [@@default-productions]
    }
  }

function _dumpTableForMold(name, table) {
  let rv = `const ${name}=`

  if (typeof(table[0]) == 'object') {
    let rowSep = ''
    rv += '[\n'
    table.forEach((row) => {
      rv += rowSep + '  [' + row.toString() + ']'
      rowSep = ',\n'
    })
    rv += '\n]';

  } else {
    rv += '[' + table.toString() + ']'
  }

  console.log(rv)
}

function _dumpTableForAsm(name, table) {
  let rv = name + ':\n'

  if (typeof(table[0]) == 'object') {
    table.forEach((row, rowIdx) => {
      rv += '  .row' + rowIdx + ' db ' + row.toString() + '\n'
    })

    rv += '  .index dq '
    let sep = ''

    table.forEach((row, rowIdx) => {
      rv += sep + '.row' + rowIdx
      sep = ', '
    })
    rv += '\n';

  } else {
    rv += '  db ' + table.toString()
  }

  console.log(rv)
}

function _dumpTable(name, table) {
//  _dumpTableForAsm(name, table)
  _dumpTableForMold(name, table)
}

function _buildUniqueRowsTable(table) {
  let uniqueRowsMap = {}
  let uniqueRows    = []

  table.forEach((row, rowIdx) => {
    const hash  = row.toString()
    let   rowId = uniqueRowsMap[hash]

    if (rowId == null) {
      rowId               = uniqueRows.length
      uniqueRowsMap[hash] = row
    }

    uniqueRows[rowId] = row
    table[rowIdx]     = rowId
  })

  return uniqueRows
}

function _sortArrayOfTriplesByFirst(table) {
  table.forEach((row, rowIdx) => {
    // Fetch row.
    const rowAsTriples = []
    for (let i = 0; i &lt; row.length; i += 3) {
      rowAsTriples.push([row[i], row[i+1], row[i+2]])
    }

    // Sort row by first field.
    rowAsTriples.sort((a, b) => {
      return a[0] - b[0]
    })

    // Store sorted array
    const newRow = []

    // TODO: Why is it needed for mold parser?
    // newRow.push(0)

    rowAsTriples.forEach((triple) => {
      newRow.push(triple[0])
      newRow.push(triple[1])
      newRow.push(triple[2])
    })

    // -1 row terminator
    newRow.push(-1)

    table[rowIdx] = newRow
  })
}

// Resolve empty emit to zero (0) opcode.
for (let idx = 0; idx &lt; data.grammar.productions.length; idx += 3) {
  if (data.grammar.productions[idx] === '') {
    data.grammar.productions[idx] = 0
  }
}

// Sort actions and goto tables for binary search.
_sortArrayOfTriplesByFirst(data.parser.action)
_sortArrayOfTriplesByFirst(data.parser.goto)

// Replace 0xffff by 0xff in LexerChars table.
// We don't support unicode.
data.lexer.chars.forEach((value, idx) => {
  if (value === 0xffff) {
    data.lexer.chars[idx] = 0xff
  }
})

// Generate LexerIndexBase table to avoid emitting
// very big numbers.
// Final index = base index + delta
const LexerIndexBaseLUT = []

data.lexer.index.forEach((row, rowIdx) => {
  // Base = minimal value in the row.
  const base = row[0]
  LexerIndexBaseLUT[rowIdx] = base

  row.forEach((col, colIdx) => {
    row[colIdx] -= base
  })
})

// Build productions table.
const GrammarProductionsLUT = []

data.grammar.productions.forEach((item) => {
  GrammarProductionsLUT.push(
    (item.emit != '') ? item.emit : 0,
    item.length,
    item.lhs
  )
})

// Build symbols greedy table.
const GrammarSymbolsGreedyLUT = []

data.grammar.symbols.forEach((item) => {
  GrammarSymbolsGreedyLUT.push(item.isGreedy)
})

// Dump tables.
_dumpTable('GrammarProductionsLUT' , GrammarProductionsLUT)
_dumpTable('SymbolsGreedyLUT'      , GrammarSymbolsGreedyLUT)

_dumpTable('ParserActionsLUT'        , data.parser.action)
_dumpTable('ParserGotoLUT'           , data.parser.goto)
_dumpTable('ParserActionsDefaultLUT' , data.parser['default-production'])

_dumpTable('LexerSelectLUT'   , data.lexer.select)
_dumpTable('LexerIndexBaseLUT', LexerIndexBaseLUT)
_dumpTable('LexerIndexLUT'    , data.lexer.index)
_dumpTable('LexerCharsLUT'    , data.lexer.chars)
_dumpTable('LexerTransLUT'    , data.lexer.transitions)
_dumpTable('LexerAcceptLUT'   , data.lexer.accept)

</file>
</generator>
